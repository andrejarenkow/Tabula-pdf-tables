{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ler arquivo PDF - tabula.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM5oX4nJQ+CiFpSdZFnQOJN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrejarenkow/Tabula-pdf-tables/blob/main/Ler_arquivo_PDF_tabula.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4tadjyRZNwV"
      },
      "source": [
        "#Instalação da biblioteca Tabula"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5rIHav_0VRz",
        "outputId": "2b91e750-9c9b-4383-e684-60e4e9c4a1f1"
      },
      "source": [
        "!pip install tabula-py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabula-py in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from tabula-py) (1.1.5)\n",
            "Requirement already satisfied: distro in /usr/local/lib/python3.7/dist-packages (from tabula-py) (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tabula-py) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->tabula-py) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.3->tabula-py) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrMkZ3IwZlad"
      },
      "source": [
        "#Importação de bibliotecas\n",
        "* Pandas\n",
        "* Tabula"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt5zFRwfZyRR"
      },
      "source": [
        "import pandas as pd\n",
        "import tabula"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TpD-qRfZrGa"
      },
      "source": [
        "#Arquivo pdf utilizado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BiSR_T9Zz3K"
      },
      "source": [
        "caminho_pdf = 'http://www.viapol.com.br/media/468572/manta-asf%C3%A1ltica-2019-laudo-de-potabilidade.pdf'\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bihZ7AJgZ9WT"
      },
      "source": [
        "#Leitura das tabelas do arquivo\n",
        "Analisando o arquivo pdf, as tabelas que nos interessam estão apenas nas páginas 1, 2, 3 e 4. Sendo assim, colocaremos este parâmetro na função *read_pdf*.\n",
        "\n",
        "Também faremos uso do parâmetro *lattice*, que refere-se a buscar tabelas que tenham linhas separadoras.\n",
        "\n",
        "Esta função devolverá uma lista de DataFrames (**dfs**), dentre os quais utilizaremos somente os dfs 3,5,6,8,9,10,12. \n",
        "\n",
        "Como queremos juntar todas tabelas em uma só, é fundamental que tenham as mesmas colunas, com os mesmos nomes, para que encaixemos uma abaixo da outra.\n",
        "\n",
        "As os dfs 5, 6, 8 e 9 iguais, sendo assim alteramos apenas os nomes das colunas com um *loop* **FOR** e concatenamos um embaixo do outro.\n",
        "\n",
        "Os dfs 3, 10 e 12 precisaram de alguns ajustes, pois não tinham as mesmas colunas, sendo necessário excluir ou incluir valores.\n",
        "\n",
        "Por fim, deletou-se as linhas que possuíam algum *NaN*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5-TCPPu6Lgs"
      },
      "source": [
        "#criação de lista de DataFrames\n",
        "dfs = tabula.read_pdf(caminho_pdf, pages=[1,2,3,4], lattice=True)\n",
        "\n",
        "#criação de um DataFrame vazio que irá juntar os outros\n",
        "df_geral = pd.DataFrame()\n",
        "\n",
        "#lista de DataFrames que são iguais\n",
        "lista_df = [dfs[5], dfs[6], dfs[8], dfs[9]]\n",
        "for i in lista_df:\n",
        "#padronização dos nomes das colunas\n",
        "  i.columns = ['ENSAIO', 'CAS', 'LIMITE DE DETECÇÃO',\n",
        "       'LIMITE DE QUANTIFICAÇÃO', 'UNIDADE',\n",
        "       'RESULTADOS antes de passar pelo corpo-de-prova OS 251088',\n",
        "       'RESULTADOS após passar pelo corpo-de-prova OS 251089',\n",
        "       '(2)VMP PORTARIA DE CONSOLIDAÇÃO B No 5',\n",
        "       'Antes de passar pelo corpo de prova-inicio','Antes de passar pelo corpo de prova-fim',\n",
        "       'Depois de passar pelo corpo de prova-inicio', 'Depois de passar pelo corpo de prova-fim', 'MÉTODO']\n",
        "\n",
        "#concatenação no DataFrame vazio\n",
        "  df_geral = pd.concat([df_geral, i])\n",
        "\n",
        "#dfs[12] tem uma coluna a mais, que será dropada\n",
        "dfs[12] = dfs[12].drop('Unnamed: 0',axis=1)\n",
        "#padronização das colunas\n",
        "dfs[12].columns = ['ENSAIO', 'CAS', 'LIMITE DE DETECÇÃO',\n",
        "       'LIMITE DE QUANTIFICAÇÃO', 'UNIDADE',\n",
        "       'RESULTADOS antes de passar pelo corpo-de-prova OS 251088',\n",
        "       'RESULTADOS após passar pelo corpo-de-prova OS 251089',\n",
        "       '(2)VMP PORTARIA DE CONSOLIDAÇÃO B No 5',\n",
        "       'Antes de passar pelo corpo de prova-inicio','Antes de passar pelo corpo de prova-fim',\n",
        "       'Depois de passar pelo corpo de prova-inicio', 'Depois de passar pelo corpo de prova-fim', 'MÉTODO']\n",
        "\n",
        "#os dfs[10] e [3] não possuem a coluna CAS, então deverão ser inseridas\n",
        "dfs[10]['CAS'] = '-'\n",
        "dfs[10].columns = ['ENSAIO', 'LIMITE DE DETECÇÃO',\n",
        "       'LIMITE DE QUANTIFICAÇÃO', 'UNIDADE',\n",
        "       'RESULTADOS antes de passar pelo corpo-de-prova OS 251088',\n",
        "       'RESULTADOS após passar pelo corpo-de-prova OS 251089',\n",
        "       '(2)VMP PORTARIA DE CONSOLIDAÇÃO B No 5',\n",
        "       'Antes de passar pelo corpo de prova-inicio','Antes de passar pelo corpo de prova-fim',\n",
        "       'Depois de passar pelo corpo de prova-inicio', 'Depois de passar pelo corpo de prova-fim', 'MÉTODO','CAS']\n",
        "\n",
        "dfs[3] = dfs[3].dropna(how='any').reset_index(drop=True)\n",
        "dfs[3].columns = ['ENSAIO', 'LIMITE DE DETECÇÃO', 'LIMITE DE QUANTIFICAÇÃO',\n",
        "       'UNIDADE',\n",
        "       'RESULTADOS antes de passar pelo corpo-de-prova OS 251088',\n",
        "       'RESULTADOS após passar pelo corpo-de-prova OS 251089',\n",
        "       '(2)VMP PORTARIA DE CONSOLIDAÇÃO B No 5',\n",
        "       'Antes de passar pelo corpo de prova-inicio','Antes de passar pelo corpo de prova-fim',\n",
        "       'Depois de passar pelo corpo de prova-inicio', 'Depois de passar pelo corpo de prova-fim', 'MÉTODO']\n",
        "dfs[3]['CAS'] = '-'\n",
        "\n",
        "\n",
        "#concatenação do resto dos dataframes\n",
        "df_geral = pd.concat([df_geral, dfs[12], dfs[10], dfs[3]])\n",
        "\n",
        "#dropando os NaN que sobraram\n",
        "df_geral.dropna(how='any', inplace=True)\n",
        "\n",
        "df_geral"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}